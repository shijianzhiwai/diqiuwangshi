---
tags: 
  - Go
  - 编程
  - fasthttp
title: 从一次线上问题排查发现的 fasthttp 设置问题
date: 2021-01-12
author: 徐徐
location: Beijing 
---

## 起因
近期由于新上的一个系统新版本出现了 bug，现象是某个 HTTP 接口会在接受一定量请求之后 hang 住，伴随着产生了大量调用方的超时报警。由于新上的系统不是面向用户的系统，所以要求运维保留现场，关掉了触发问题请求的任务，开始排查问题。

最后找到问题的原因很简单：sqlx 库使用了 Queryx 方法，查询由于只是判断记录是否存在，所以并没有读取返回的 Rows，这就导致了一个问题，就是数据库连接不会被释放回池子里，由于设置了最大连接数，所以导致接口被 hang 死。

这里也有了一个教训，无论是什么级别的系统，还是在测试环境多跑跑。

言归正传，今天要讨论的主题并不是这个低级错误。在修复完 bug 之后，由于之前的服务一直保留现场，所以修复的代码打包完成后直接在公司内部的 k8s 平台操作上线了，这时产生了一个诡异的现象，突然之间收到了大约三千多个请求，似乎是之前被 hang 住的请求被复活一样。

这就诡异了。

接下来就是搞清楚这个问题，比较担心是某些未知的 bug 导致的。

## 排查调用方请求日志

我先从这三千多个请求中随机挑选了几个，由于每个请求都有 TraceId，所以直接去请求方日志中搜寻，发现这些请求的确是在故障发生时候请求的，并且还有请求超时的错误信息。在服务修复之后上线重启的时间段，并没有对应的请求日志。

这就很奇怪，难道是日志本身的问题？通过拉取调用方服务的代码（同组服务，有对应权限），发现这一块就是很简单的出现 err，打印日志的逻辑。的确，一般这种思考肯定不会是问题的原因。

> 至于真相，一定更在意料之外 —— 自古皆然。
>
> -- <cite>阿瑟·克拉克</cite>

## 问题复现

在排查调用方服务的时候发现，HTTP 请求是使用的 fasthttp 库，代码也很简单，大致逻辑如下：

```go
fasthttp.DoTimeout(req, resp, time.Second)
```

代码中设置了超时时间，这个很好理解，